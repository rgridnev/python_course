{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Воспроизведение \"King James Programming\" для русского языка, или \"Ветхий алгоритм\"\n",
    "\n",
    "http://kingjamesprogramming.tumblr.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мотивация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для английского языка есть марковская цепь, натренированная на книгах King James Bible, Structure and Interpretation of Computer Programs, и некоторых записках Эрика Раймонда.\n",
    "\n",
    "Модель генерирует такие замечательные высказывания, как:\n",
    "> hath it not been for the singular taste of old Unix, “new Unix” would not exist\n",
    "\n",
    "Или, моё любимое,\n",
    "> The interpreter will run slowly this time because of the will of the LORD.\n",
    "\n",
    "Я подумала и решила: а почему бы не сделать такое для русского?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\"[А-Яа-яA-Za-z!?.]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    return \" \".join(regex.findall(str(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве обучающих текстов я взяла Ватхий Завет и книги \"Вводный курс алгоритмов\" (Кормен) и \"UNIX. Профессиональное программирование\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " от воды. [И стало так.]\n",
      "7 И создал Бог твердь, и отделил воду, которая под твердью, от воды, котора\n",
      "***\n",
      "\n",
      "== Бытие ==\n",
      "\n",
      "=== 1 ===\n",
      "\n",
      "1 В начале сотворил Бог небо и землю.\n",
      "2 Земля же была безвидна и пуста, и тьма над бездною, и Дух Божий носился над водою.\n",
      "3 И сказал Бог: да будет свет. И стал свет.\n",
      "4 И увидел Бог свет, что он хорош, и отделил Бог свет от тьмы.\n",
      "5 И назвал Бог свет днем, а тьму ночью. И был вечер, и было утро: день один.\n",
      "6 И сказал Бог: да будет твердь посреди воды, и да отделяет она воду от воды. [И стало так.]\n",
      "7 И создал Бог твердь, и отделил воду, которая под твердью, от воды, котора\n",
      "4164321\n"
     ]
    }
   ],
   "source": [
    "# читаем ветхий завет\n",
    "with open('bible.txt', encoding='cp1251') as f:\n",
    "    bible = f.read()\n",
    "    print(bible[400:500])\n",
    "    print('***')\n",
    "#     bible = bible[700:] # там было странное\n",
    "#     bible = bible[:-365]\n",
    "print(bible[:500])\n",
    "print(len(bible))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible = words_only(bible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Бытие \n",
      "\n",
      " 1 \n",
      "\n",
      "В начале сотворил Бог небо и землю.\n",
      "Земля же была безвидна и пуста, и тьма над бездною, и Дух Божий носился над водою.\n",
      "И сказал Бог: да будет свет. И стал свет.\n",
      "И увидел Бог свет, что он хорош, и отделил Бог свет от тьмы.\n",
      "И назвал Бог свет днем, а тьму ночью. И был вечер, и было утро: день один.\n",
      "И сказал Бог: да будет твердь посреди воды, и да отделяет она воду от воды. [И стало так.]\n",
      "И создал Бог твердь, и отделил воду, которая под твердью, от воды, которая над твердью. И стало т\n"
     ]
    }
   ],
   "source": [
    "# чистим ветхий завет\n",
    "bible = [re.sub('^[0-9]+ ', '', l) for l in bible.split('\\n')]\n",
    "bible = '\\n'.join(bible).replace('=', '')\n",
    "print(bible[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сура 1\n",
      "        Открывающая Книгу\n",
      "      \n",
      "      1. (1). Во имя Аллаха милостивого, милосердного! (2). Хвала — Аллаху, Господу миров,\n",
      "      2. (3). милостивому, милосердному,\n",
      "      3. (4). царю в день суда!\n",
      "      4. (5). Тебе мы поклоняемся и просим помочь!\n",
      "      5. (6). Веди нас по дороге прямой,\n",
      "      6. (7). по дороге тех, которых Ты облагодетельствовал,\n",
      "      7. не тех, которые находятся под гневом, и не заблудших.\n",
      "      \n",
      "    \n",
      "      \n",
      "        Сура 2\n",
      "        Корова\n",
      "      \n",
      "      1. (1). Алм. (2).\n",
      "812012\n"
     ]
    }
   ],
   "source": [
    "# Читаем коран\n",
    "with open('koran.txt', encoding=\"utf-8\") as f:\n",
    "    koran = f.read()\n",
    "    koran = koran[137:]\n",
    "print(koran[:500])\n",
    "print(len(koran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "koran = words_only(koran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1. Предисловие\n",
      "\n",
      "     В  последнее  время  Internet  очень  часто  оказывается в центре\n",
      "внимания,  и серьезные люди часто болтаются по этому \" Информационному\n",
      "супершоссе\". Компьютерные сети становятся такими же обыденными вещами,\n",
      "как  телевизоры  и  микроволновые  печи.  Inetrnet  получает  необычно\n",
      "широкое  освещение  в  печати, а ученые обсуждают в Usenet возможность\n",
      "проведения   исследований   \"Internet  культуры.\"  Различные  компании\n",
      "работают над новыми методами передачи данных, например ATM, которые во\n",
      "многих  случаях  позволяют  получить  большую  скорость  передачи, чем\n",
      "сейчас.\n",
      "\n",
      "     Конечно,   сети  развивались  достаточно  долгое  время.  Обычной\n",
      "практикой   было   создание  маленьких  локальных  сетей,  в  основном\n",
      "распологавшихся в одном здании, и соединенных через обычные телефонные\n",
      "линии.   Таким   образом,  быстро  разраставшийся  конгломерат  сетей,\n",
      "позволял  подсоединятся  к  этой  глобальной  системе  даже  маленьким\n",
      "некоммерческим  организациям и частным пользователям. Поэтому создание\n",
      "Internet-хоста   с   почтой   и  новостями,  предлагающего  доступ  по\n",
      "телефону,   стало   нормальной  практикой,  и  появление  ISDN  будет,\n",
      "несомненно, ускорять эту тенденцию.\n",
      "\n",
      "     Разговор  о  компьютерных  сетях  очень часто означает разговор о\n",
      "UNIX.  Конечно,  UNIX - не единственная сетевая операционная система и\n",
      "не  всегда  она  будет  лидером,  но умрет она очень не скоро. Поэтому\n",
      "особенно  интересным  для пользователя становится появление бесплатных\n",
      "UNIXоидных  о\n",
      "1698584\n"
     ]
    }
   ],
   "source": [
    "# Читаем юникс\n",
    "with open('unix.txt', encoding=\"utf-8\") as f:\n",
    "    unix = f.read()\n",
    "#     unix = unix[82500:]\n",
    "print(unix[:1500])\n",
    "print(len(unix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чистим юникс\n",
    "unix = words_only(unix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генератор предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Готовая имплементация марковской цепи\n",
    "\n",
    "https://github.com/jsvine/markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5625234"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = bible + koran + unix[:10 ** 6]\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_m = markovify.Text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "И сказал мне на небе?\n",
      "Сура Железо . . Разве для людей которые знают!\n",
      "Многие же постилали одежды свои Иисус сел на улице городской.\n",
      "И делал он неугодное в очах Господних точно так как десятину сынов Израилевых они не отвечали ему ни слова.\n",
      "И помогали ему и сказал с миром отпущены были братиями к Апостолам.\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(text_m.make_sentence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... безудержное веселье! \n",
    "* Мы начнем со строки Х и будем твердо стоять за народ наш и за беззакония наши преданы были мы, цари наши, священники наши и дети мои вокруг меня, когда светильник Его светил над головою моею, и я забросил клюшку и щиток.\n",
    "* Но ведь тоrда тщательно выверенная процедура PARTIТION не будет живущих, ибо, кого Ты поразил, они *еще* преследуют, и страдания уязвленных Тобою умножают.\n",
    "* Шаг 2 выполняется ровно n раз, потому что ячмень выколосился, а лен осеменился; а пшеница и полба не побиты, потому что Господь зовет отрока.\n",
    "* Иосиф узнал братьев своих, сыновей царя, со всеми слугами своего господина, и не может сразу следовать за выводом без вызова функций fseek, fsetpos или rewind.\n",
    "* Однако когда программа, использовавшая эту возможность, запускала командную оболочку, чтобы воздействовать на все дни жизни твоей; и очистит священник душу, сделавшую по ошибке согрешит против ближнего своего;\n",
    "* И из сыновей Заффу: Елиоенай, Елияшив, Матфания, Иремоф, Завад и Азиса; и из сыновей своих, чтоб он спас нас от беспокойства по поводу буферизации или оптимальности выбранного размера буфера\n",
    "* Жене сказал: умножая умножу потомство твое, так что каждый вызов read или write обращается к системному вызову ядра.\n",
    "* При захождении солнца приказал Иисус, и сняли их с площади Беф-Сана, где они были перенаправлены в файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраним его\n",
    "with open('lm.bin', 'wb') as f:\n",
    "    pickle.dump(text_m, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\photo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Напишем свой генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Бытие',\n",
       " 'В',\n",
       " 'начале',\n",
       " 'сотворил',\n",
       " 'Бог',\n",
       " 'небо',\n",
       " 'и',\n",
       " 'землю',\n",
       " '.',\n",
       " 'Земля',\n",
       " 'же',\n",
       " 'была',\n",
       " 'безвидна',\n",
       " 'и',\n",
       " 'пуста',\n",
       " 'и',\n",
       " 'тьма',\n",
       " 'над',\n",
       " 'бездною',\n",
       " 'и']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "corpus = word_tokenize(text)\n",
    "corpus[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1914 34\n"
     ]
    }
   ],
   "source": [
    "freq = nltk.FreqDist(corpus)\n",
    "print(freq['Бог'], freq['вызов'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfreq = nltk.ConditionalFreqDist(nltk.bigrams(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in cfreq['функция']:\n",
    "    if key[0] in 'йцукенгшщзхфывапролджэячсмитьбю' and cfreq['функция'][key] > 2:\n",
    "        print(key, cfreq['функция'][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Бытие', 'В', 'Бог', 'Земля', 'Дух', 'Божий', 'И', 'Бог', 'И', 'И']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capitalized = [w for w in corpus if w[0].isupper()]\n",
    "capitalized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cprob = nltk.ConditionalProbDist(cfreq, nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция, которая генерирует предложение из n слов на основании предыдущего слова\n",
    "import random\n",
    "def gen_n_words(n, first_word=None):\n",
    "    if first_word is None:\n",
    "        first_word = random.choice(capitalized)\n",
    "    sent = [first_word]\n",
    "    for i in range(n - 1):\n",
    "        next_w = cprob[sent[-1]].generate()\n",
    "        sent.append(next_w)\n",
    "    return ' '.join(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Когда же принеся в конец файла проекта . И сказал Моисей\n",
      "Павел сказал Саул еще не получали их в одиночестве\n",
      "Иависа . Посему так то существует и язык\n",
      "Авариме на которую пещеру Одоллам и в тот\n",
      "Разве ты совершила обеты и повел бы менее сей\n",
      "Но вы совершили они с нею полагая что у\n",
      "Его и стрелы Свои знамения малую единицу . И скажи\n",
      "Когда же возврати мне ? Запишется их при нем нечистота\n",
      "Зачем мятутся язычники и Манассии\n",
      "Это происходит не принимает Пославшего Меня от зла\n",
      "Я Господь избавил народ мой . Так приносите сие братиям живущим на овна в usr\n",
      "И собрались вместе с Иудеями мир . Мы уже сходили они поражены Израильтянами и которые\n",
      "Иорам и из миров . Придя к преступлениям и они и говорить\n",
      "На личность ли все ободрились и вы были распростерты расходует\n",
      "Израилев могут войти . Наклонность\n",
      "Нему чтобы умножилась неправда .\n",
      "Иудее пророк Иеремия царю . Если она найдена в груди . И Ты знаешь видишь\n",
      "Мы создали то попирает его Господь долготерпелив и взойдя на\n",
      "Тотчас собрались первосвященники и преследовал их и грех свой\n",
      "И поселился Ионафан и очами Твоими знамениями к Давиду в\n"
     ]
    }
   ],
   "source": [
    "lengths = [5, 6, 7, 8, 8, 9, 9, 10, 10, 10, 11, 11, 12, 13, 14, 15]\n",
    "for i in range(20):\n",
    "    n = random.choice(lengths)\n",
    "    print(gen_n_words(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNIX сфере в которые владели ничем таковым . . Посему'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_n_words(10, first_word='UNIX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'алгоритм только половина колена дано место для вас в предыдущей даты очень'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_n_words(12, first_word='алгоритм')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то порождать самостоятельно получается, но очень много мусора. Возьмём лучше готовую имплементаию марковской цепи и попытаемся улучшить комедийный эффект."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План по захвату мира\n",
    "\n",
    "**Проблема**: не все предложения смешные -- большая часть представляет собой либо что-то библиеподобное, либо программистское.\n",
    "\n",
    "**Задача**: автоопределять смешные предложения, то есть отлавливать такие предложения, которые, с болбшой вероятностью, содержат слова и из библии, и из программирования.\n",
    "\n",
    "**Пути решения**:\n",
    "* через tf-idf\n",
    "* классификатор, выдающий вероятности!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "testament = sent_tokenize(bible + koran)\n",
    "# testament = sent_tokenize(koran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Бытие В начале сотворил Бог небо и землю.', 'Земля же была безвидна и пуста и тьма над бездною и Дух Божий носился над водою.', 'И сказал Бог да будет свет.', 'И стал свет.', 'И увидел Бог свет что он хорош и отделил Бог свет от тьмы.', 'И назвал Бог свет днем а тьму ночью.', 'И был вечер и было утро день один.', 'И сказал Бог да будет твердь посреди воды и да отделяет она воду от воды.', 'И стало так.', 'И создал Бог твердь и отделил воду которая под твердью от воды которая над твердью.', 'И стало так.', 'И назвал Бог твердь небом.', 'И увидел Бог что это хорошо.', 'И был вечер и было утро день второй.', 'И сказал Бог да соберется вода которая под небом в одно место и да явится суша.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55072"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testament[:15])\n",
    "len(testament)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.', 'Предисловие В последнее время Internet очень часто оказывается в центре внимания и серьезные люди часто болтаются по этому Информационному супершоссе .', 'Компьютерные сети становятся такими же обыденными вещами как телевизоры и микроволновые печи.', 'Inetrnet получает необычно широкое освещение в печати а ученые обсуждают в Usenet возможность проведения исследований Internet культуры.', 'Различные компании работают над новыми методами передачи данных например ATM которые во многих случаях позволяют получить большую скорость передачи чем сейчас.', 'Конечно сети развивались достаточно долгое время.', 'Обычной практикой было создание маленьких локальных сетей в основном распологавшихся в одном здании и соединенных через обычные телефонные линии.', 'Таким образом быстро разраставшийся конгломерат сетей позволял подсоединятся к этой глобальной системе даже маленьким некоммерческим организациям и частным пользователям.', 'Поэтому создание Internet хоста с почтой и новостями предлагающего доступ по телефону стало нормальной практикой и появление ISDN будет несомненно ускорять эту тенденцию.', 'Разговор о компьютерных сетях очень часто означает разговор о UNIX.', 'Конечно UNIX не единственная сетевая операционная система и не всегда она будет лидером но умрет она очень не скоро.', 'Поэтому особенно интересным для пользователя становится появление бесплатных UNIXоидных операционных систем для PC BSD FreeBSD и Linux .', 'Однако Linux не UNIX.', 'Unix зарегистрированная торговая марка кто бы в настоящее время не держал права на него в то время как Linux oперационная система которая стремится предложить все функциональные возможности требующие POSIX стандарты для UNIX подобных операционных систем.', 'Ядро Linux было написано в значительной степени Linus Torvalds человеком который начал это проект чтобы понять как работает Intel i и MINIX.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29089"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coding = sent_tokenize(unix+unix)\n",
    "print(coding[:15])\n",
    "len(coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = testament + coding\n",
    "labels = ['testament'] * len(testament) + ['coding'] * len(coding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Бытие В начале сотворил Бог небо и землю.</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Земля же была безвидна и пуста и тьма над безд...</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>И сказал Бог да будет свет.</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>И стал свет.</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>И увидел Бог свет что он хорош и отделил Бог с...</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences     labels\n",
       "0          Бытие В начале сотворил Бог небо и землю.  testament\n",
       "1  Земля же была безвидна и пуста и тьма над безд...  testament\n",
       "2                        И сказал Бог да будет свет.  testament\n",
       "3                                       И стал свет.  testament\n",
       "4  И увидел Бог свет что он хорош и отделил Бог с...  testament"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'sentences' : sentences, 'labels': labels})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UUCPNAME разрешает Вам определять различные ho...</td>\n",
       "      <td>coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Что возлюбленному Моему в доме Моем когда в не...</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>У Аллаха величие и у Его посланника и у верующ...</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Предел Манассии на северной стороне потока и о...</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Если вы вызываете pall используя следующую ком...</td>\n",
       "      <td>coding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Из них буду брать также в священники и левиты ...</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Впрочем близок всему конец.</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>И вышел Иона из города и сел с восточной сторо...</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>О да погибнут адиты народ Худа!</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Тогда говорит ученикам Своим жатвы много а дел...</td>\n",
       "      <td>testament</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences     labels\n",
       "0  UUCPNAME разрешает Вам определять различные ho...     coding\n",
       "1  Что возлюбленному Моему в доме Моем когда в не...  testament\n",
       "2  У Аллаха величие и у Его посланника и у верующ...  testament\n",
       "3  Предел Манассии на северной стороне потока и о...  testament\n",
       "4  Если вы вызываете pall используя следующую ком...     coding\n",
       "5  Из них буду брать также в священники и левиты ...  testament\n",
       "6                        Впрочем близок всему конец.  testament\n",
       "7  И вышел Иона из города и сел с восточной сторо...  testament\n",
       "8                    О да погибнут адиты народ Худа!  testament\n",
       "9  Тогда говорит ученикам Своим жатвы много а дел...  testament"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перемешаем данные\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# и сохраним, а то сколько можно\n",
    "df.to_csv('bible_vs_coding.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"mv\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "!mv bible_vs_coding.csv data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['sentences'], df['labels'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stopset = stopwords.words('russian')\n",
    "stopset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punct = list(punctuation)\n",
    "punct[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "def preproc_lemmitize(text):\n",
    "#     m = Mystem()\n",
    "#     text = m.lemmatize(text.lower()) # приводим к нижнему регистру и токенизируем\n",
    "    return [w for w in text if w not in stopset + punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', 'сказать', ' ', 'бог', ': ', ' ', ' ', 'свет', '\\n']"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc_lemmitize('И сказал Бог: да будет свет.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед наивным Байесом я попробовала DecisionTreeClassifier. Он работал с f-мерой ~96, но очень плохо выдавал условные вероятности (в основном 0.0, 1.0). У MultinomialNB и лучше f-мера, и условные вероятности позволяют принимать решение о \"нетипичности\" фразы.\n",
    "\n",
    "Препроцессинг с помощью mystem работал слишком долго."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', TfidfVectorizer(min_df=10)),\n",
       "                ('tree', RandomForestClassifier())])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dt = Pipeline(\n",
    "#     [('vect', TfidfVectorizer(min_df=10)),\n",
    "#     ('tree', DecisionTreeClassifier(random_state=42))]\n",
    "# )\n",
    "\n",
    "dt = Pipeline(\n",
    "    [('vect', TfidfVectorizer(min_df=10)),\n",
    "    ('tree', RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "dt.fit(X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      coding       0.99      0.88      0.93      5831\n",
      "   testament       0.94      0.99      0.97     11002\n",
      "\n",
      "    accuracy                           0.95     16833\n",
      "   macro avg       0.96      0.94      0.95     16833\n",
      "weighted avg       0.96      0.95      0.95     16833\n",
      "\n",
      "0.9547317768668686\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dt.predict(X_test)))\n",
    "print(accuracy_score(y_test, dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(min_df=5,\n",
       "                                 tokenizer=<function my_preprocessor at 0x0000015EC43445E0>)),\n",
       "                ('nb', RandomForestClassifier())])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ppl = Pipeline(\n",
    "#     [('vect', TfidfVectorizer(min_df=5, tokenizer=my_preprocessor)),\n",
    "#     ('nb', MultinomialNB())]\n",
    "# )\n",
    "ppl = Pipeline(\n",
    "    [('vect', TfidfVectorizer(min_df=5, tokenizer=my_preprocessor)),\n",
    "    ('nb', RandomForestClassifier())]\n",
    ")\n",
    "ppl.fit(X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      coding       0.98      0.89      0.93      5831\n",
      "   testament       0.94      0.99      0.97     11002\n",
      "\n",
      "    accuracy                           0.95     16833\n",
      "   macro avg       0.96      0.94      0.95     16833\n",
      "weighted avg       0.96      0.95      0.95     16833\n",
      "\n",
      "0.9548505911008138\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, ppl.predict(X_test)))\n",
    "print(accuracy_score(y_test, ppl.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04, 0.96]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.predict_proba(['Но ведь тоrда тщательно выверенная процедура PARTIТION не будет живущих, ибо'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Урааа, работает! Теперь можно захватывать мир."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.44999185 0.55000815]]\n",
      "[[8.34707322e-04 9.99165293e-01]]\n",
      "[[0.94402701 0.05597299]]\n"
     ]
    }
   ],
   "source": [
    "print(ppl.predict_proba(['Шаг 2 выполняется ровно n раз, потому что ячмень выколосился, а лен осеменился; а пшеница и полба не побиты, потому что Господь зовет отрока.']))\n",
    "print(ppl.predict_proba(['Потом пошел Авимелех на гору Селмон, сам и дом царский для себя.']))\n",
    "print(ppl.predict_proba(['Процедура Bu1LD-HUFFМAN-TREE служит примером жадного алгоритма, в котором длина строк превышает 4 байта?']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# и модель сохраним, давно пора\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('algtest_classifyer.clf', 'wb') as f:\n",
    "    pickle.dump(ppl, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"ls\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "!ls -lh *.clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Захват мира\n",
    "\n",
    "Напишем функцию, которая находит что-то весёлое:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isFunny(sent, model, min_p, max_p):\n",
    "    return min_p < model.predict_proba([sent])[0][1] < max_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Настройки функции**: с min_p и max_p можно играться. Наибольшая точность достигается в районе 0.01 и 0.97 соответственно. Однако, так как нас не так сильно беспокоят false negative -- главное, чтобы не было false positive -- лучше сделать этот порог повыше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аллах захотел ходить по букве ему также\n",
      "\n",
      "Аллах не являются so NORM e E X сеанс работы чтобы он\n",
      "\n",
      "Аллах сделает то они скажут им для систем \n",
      "\n",
      "Аллах наблюдатель  Он вызывает команду которая была на носителе\n",
      "\n",
      "Аллах говорит Господь море и надежный доступ пользователей могут они неусыпно пекутся\n",
      "\n",
      "Аллах знает то что будет прибавить линии только\n",
      "\n",
      "Аллах держит информацию  Ибо\n",
      "\n",
      "Аллах отрекается от лукавства  Для систем\n",
      "\n",
      "Аллах не клевещите и полей с нами   У\n",
      "\n",
      "Аллах приведет муж поспешил выдать arp v   Но рушится\n",
      "\n",
      "Аллах знает NYS использовал именованный сервер через\n",
      "\n",
      "Аллах подчинил солнце и жена неверующая освящается словом истины которая есть\n",
      "\n",
      "Аллах  а если следующая строка и располагал воду покупайте у детей\n",
      "\n",
      "Аллах тех кому оказалось их использовать\n",
      "\n",
      "Аллах пожелал сами назвали эти имена файлов\n",
      "\n",
      "Аллах устроил   и сказал мне с места поиск в Приложении\n",
      "\n",
      "Аллах благодарен  incoming  Вот что smail  Вы\n",
      "\n",
      "Аллах слышащий ведающий скрытое в задние части ядра который наречен\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "#     sent = text_m.make_sentence()\n",
    "    sent = gen_n_words(random.randint(5,12), first_word='Аллах')\n",
    "    if isFunny(sent, ppl, 0.01, 0.97) == True:\n",
    "        print(re.sub(r'[^\\w\\s]','', sent))\n",
    "        print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
